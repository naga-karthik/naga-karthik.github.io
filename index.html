<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Naga Karthik Enamundram </title> <meta name="author" content="Naga Karthik Enamundram"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://naga-karthik.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About Me <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Naga Karthik</span> Enamundram </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?8a65768c8b7138eb45df5fb7a8cfacb6" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi there! I‚Äôm Naga, a fourth-year PhD student at <a href="https://neuro.polymtl.ca" rel="external nofollow noopener" target="_blank">NeuroPoly</a>, Polytechnique Montr√©al. I‚Äôm also affiliated to <a href="https://mila.quebec/en" rel="external nofollow noopener" target="_blank">Mila - Qu√©bec AI Institute</a>. During my PhD, I worked on developing deep learning-based methods for medical image analysis, with a particular focus on improving the estimation of imaging biomarkers using real-world spinal cord imaging data. I have developed automatic tools for segmentation of the spinal cord and lesions across various MRI contrasts and pathologies such as spinal cord injury (SCI), multiple sclerosis (MS) and degenerative cervical myelopathy (DCM). I have also experimented with generative modelling, in particular, training GANs for cross-modality MR-CT synthesis and diffusion models for synthesizing spinal cord lesions. In the past, I have also worked on the application of continual/lifelong learning methods for the segmentation of brain MS lesions. Please head to my <a href="https://scholar.google.com/citations?user=ZryIoMMAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a> profile for a complete list of my publications.</p> <p>When I am not working, you‚Äôll find me either running <img class="emoji" title=":running:" alt=":running:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c3.png" height="20" width="20">, hiking <img class="emoji" title=":mountain:" alt=":mountain:" src="https://github.githubassets.com/images/icons/emoji/unicode/26f0.png" height="20" width="20">, or reading <img class="emoji" title=":book:" alt=":book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png" height="20" width="20">.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 30vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 25, 2025</th> <td> Our paper ‚Äú<a href="https://arxiv.org/pdf/2508.01713" rel="external nofollow noopener" target="_blank">Dynamic Robot-Assisted Surgery with Hierarchical Class-Incremental Semantic Segmentation</a>‚Äù was accepted at MICCAI workshop on Applications of Medical Artificial Intelligence (AMAI) 2025 in Daejon, South Korea! üá∞üá∑ </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 13, 2025</th> <td> I was featured in the <a href="https://www.unique.quebec" rel="external nofollow noopener" target="_blank">UNIQUE-Qu√©bec</a> Newsletter as part of their student spotlight series! Please find the newsletter <a href="https://drive.google.com/file/d/1QAUg3TwfB2ygj8cFpwZACkK-9L18Z75C/view?usp=sharing" rel="external nofollow noopener" target="_blank">here</a>. üì∞ </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 13, 2025</th> <td> Our paper ‚Äú<a href="https://www.sciencedirect.com/science/article/pii/S1361841525000210" rel="external nofollow noopener" target="_blank">Towards contrast-agnostic soft segmentation of the spinal cord</a>‚Äù was accepted at the Medical Image Analysis journal (Impact Factor: 10.7)! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 19, 2024</th> <td> Our paper ‚Äú<a href="https://arxiv.org/pdf/2407.17265" rel="external nofollow noopener" target="_blank">SCIsegV2: A Universal Tool for Segmentation of Intramedullary Lesions in Spinal Cord Injury</a>‚Äù was accepted at MICCAI Applications of Medical Artificial Intelligence (AMAI) Workshop 2024 in Marrakech, Morocco! üá≤üá¶ </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 07, 2024</th> <td> I was awarded the <a href="https://www.daad-canada.ca/en/find-funding/graduate-opportunities/research-grants/short-term-research-grants/" rel="external nofollow noopener" target="_blank">DAAD Short-term Research Grant</a> for a 4-month research stay at the Technical University of Munich, Germany! ü•® üá©üá™ </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 02, 2024</th> <td> Our recent works on contrast-agnostic spinal cord segmentation and segmentation of spinal cord injury lesions were accepted for Oral Presentations at the 2024 ISMRM &amp; ISMRT Annual Meeting &amp; Exhibition in Singapore <img class="emoji" title=":singapore:" alt=":singapore:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1f8-1f1ec.png" height="20" width="20"> ! </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 22, 2023</th> <td> I gave a talk on Automatic Segmentation of Brain and Spinal Cord Lesions across Pathologies at the <a href="https://unique-students.github.io" rel="external nofollow noopener" target="_blank">UNIQUE Fellows Get-Together</a>, held at <a href="https://mila.quebec/en" rel="external nofollow noopener" target="_blank">Mila</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 05, 2022</th> <td> Honoured to receive the <a href="https://www.gg.ca/en/honours/governor-generals-awards/governor-generals-academic-medal" rel="external nofollow noopener" target="_blank">Governor General of Canada‚Äôs Academic Gold Medal</a> for outstanding academic achievements during my master‚Äôs at √âTS! üèÖ üá®üá¶ </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <img src="/assets/img/publication_preview/lifelong_ca_final.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lifelong_ca_final.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="karthik2025monitoringmorphometricdriftlifelong" class="col-sm-8"> <div class="title">Monitoring morphometric drift in lifelong learning segmentation of the spinal cord</div> <div class="author"> Enamundram Naga Karthik, Sandrine B√©dard, Jan Valo≈°ek, and <span class="more-authors" title="click to view 53 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '53 more authors' ? 'Christoph S. Aigner, Elise Bannier, Josef Bedna≈ô√≠k, Virginie Callot, Anna Combes, Armin Curt, Gergely David, Falk Eippert, Lynn Farner, Michael G Fehlings, Patrick Freund, Tobias Granberg, Cristina Granziera, RHSCIR Network Imaging Group, Ulrike Horn, Tom√°≈° Hor√°k, Suzanne Humphreys, Markus Hupp, Anne Kerbrat, Nawal Kinany, Shannon Kolind, Petr Kudliƒçka, Anna Lebret, Lisa Eunyoung Lee, Caterina Mainero, Allan R. Martin, Megan McGrath, Govind Nair, Kristin P. O‚ÄôGrady, Jiwon Oh, Russell Ouellette, Nikolai Pfender, Dario Pfyffer, Pierre-Fran√ßois Pradat, Alexandre Prat, Emanuele Pravat√†, Daniel S. Reich, Ilaria Ricchi, Naama Rotem-Kohavi, Simon Schading-Sassenhausen, Maryam Seif, Andrew Smith, Seth A Smith, Grace Sweeney, Roger Tam, Anthony Traboulsee, Constantina Andrada Treaba, Charidimos Tsagkas, Zachary Vavasour, Dimitri Van De Ville, Kenneth Arnold Weber II, Sarath Chandar, Julien Cohen-Adad' : '53 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">53 more authors</span> </div> <div class="periodical"> <em>arXiv</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2505.01364" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/sct-pipeline/contrast-agnostic-softseg-spinalcord" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=ZryIoMMAAAAJ&amp;citation_for_view=ZryIoMMAAAAJ:KlAtU1dfN6UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Morphometric measures derived from spinal cord segmentations can serve as diagnostic and prognostic biomarkers in neurological diseases and injuries affecting the spinal cord. While robust, automatic segmentation methods to a wide variety of contrasts and pathologies have been developed over the past few years, whether their predictions are stable as the model is updated using new datasets has not been assessed. This is particularly important for deriving normative values from healthy participants. In this study, we present a spinal cord segmentation model trained on a multisite (n=75) dataset, including 9 different MRI contrasts and several spinal cord pathologies. We also introduce a lifelong learning framework to automatically monitor the morphometric drift as the model is updated using additional datasets. The framework is triggered by an automatic GitHub Actions workflow every time a new model is created, recording the morphometric values derived from the model‚Äôs predictions over time. As a real-world application of the proposed framework, we employed the spinal cord segmentation model to update a recently-introduced normative database of healthy participants containing commonly used measures of spinal cord morphometry. Results showed that: (i) our model outperforms previous versions and pathology-specific models on challenging lumbar spinal cord cases, achieving an average Dice score of 0.95 ¬± 0.03; (ii) the automatic workflow for monitoring morphometric drift provides a quick feedback loop for developing future segmentation models; and (iii) the scaling factor required to update the database of morphometric measures is nearly constant among slices across the given vertebral levels, showing minimum drift between the current and previous versions of the model monitored by the framework. The model is freely available in Spinal Cord Toolbox v7.0.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">karthik2025monitoringmorphometricdriftlifelong</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Monitoring morphometric drift in lifelong learning segmentation of the spinal cord}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Karthik, Enamundram Naga and B√©dard, Sandrine and Valo≈°ek, Jan and Aigner, Christoph S. and Bannier, Elise and Bedna≈ô√≠k, Josef and Callot, Virginie and Combes, Anna and Curt, Armin and David, Gergely and Eippert, Falk and Farner, Lynn and Fehlings, Michael G and Freund, Patrick and Granberg, Tobias and Granziera, Cristina and Group, RHSCIR Network Imaging and Horn, Ulrike and Hor√°k, Tom√°≈° and Humphreys, Suzanne and Hupp, Markus and Kerbrat, Anne and Kinany, Nawal and Kolind, Shannon and Kudliƒçka, Petr and Lebret, Anna and Lee, Lisa Eunyoung and Mainero, Caterina and Martin, Allan R. and McGrath, Megan and Nair, Govind and O'Grady, Kristin P. and Oh, Jiwon and Ouellette, Russell and Pfender, Nikolai and Pfyffer, Dario and Pradat, Pierre-Fran√ßois and Prat, Alexandre and Pravat√†, Emanuele and Reich, Daniel S. and Ricchi, Ilaria and Rotem-Kohavi, Naama and Schading-Sassenhausen, Simon and Seif, Maryam and Smith, Andrew and Smith, Seth A and Sweeney, Grace and Tam, Roger and Traboulsee, Anthony and Treaba, Constantina Andrada and Tsagkas, Charidimos and Vavasour, Zachary and Ville, Dimitri Van De and II, Kenneth Arnold Weber and Chandar, Sarath and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2505.01364}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CV}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2505.01364}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Imaging Neuroscience</abbr> <figure> <picture> <img src="/assets/img/publication_preview/msseg_bavaria.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="msseg_bavaria.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="karthik2025automatic" class="col-sm-8"> <div class="title">Automatic segmentation of spinal cord lesions in MS: A robust tool for axial T2-weighted MRI scans</div> <div class="author"> Enamundram Naga Karthik<sup>*</sup>, Julian McGinnis<sup>*</sup>, Ricarda Wurm, and <span class="more-authors" title="click to view 17 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '17 more authors' ? 'Sebastian Ruehling, Robert Graf, Jan Valosek, Pierre-Louis Benveniste, Markus Lauerer, Jason Talbott, Rohit Bakshi, Shahamat Tauhid, Timothy Shepherd, Achim Berthele, Claus Zimmer, Bernhard Hemmer, Daniel Rueckert, Benedikt Wiestler, Jan S. Kirschke, Julien Cohen-Adad, Mark M√ºhlau' : '17 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">17 more authors</span> </div> <div class="periodical"> <em>Imaging Neuroscience</em>, Jun 2025 </div> <div class="periodical"> *shared first authorship </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1162/IMAG.a.45" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://direct.mit.edu/imag/article-pdf/doi/10.1162/IMAG.a.45/2528780/imag.a.45.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ivadomed/model-seg-ms-axial-t2w" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=ZryIoMMAAAAJ&amp;citation_for_view=ZryIoMMAAAAJ:5nxA0vEk-isC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Deep learning models have achieved remarkable success in segmenting brain white matter lesions in multiple sclerosis (MS), becoming integral to both research and clinical workflows. While brain lesions have gained significant attention in MS research, the involvement of spinal cord lesions in MS is relatively understudied. This is largely owing to the variability in spinal cord magnetic resonance imaging (MRI) acquisition protocols, high individual anatomical differences, the complex morphology and size of spinal cord lesions, and lastly, the scarcity of labeled datasets required to develop robust segmentation tools. As a result, automatic segmentation of spinal cord MS lesions remains a significant challenge. Although some segmentation tools exist for spinal cord lesions, most have been developed using sagittal T2-weighted (T2w) sequences primarily focusing on cervical spines. With the growing importance of spinal cord imaging in MS, axial T2w scans are becoming increasingly relevant due to their superior sensitivity in detecting lesions compared to sagittal acquisition protocols. However, most existing segmentation methods struggle to effectively generalize to axial sequences due to differences in image characteristics caused by the highly anisotropic spinal cord scans. To address these challenges, we developed a robust, open-source lesion segmentation tool tailored specifically for axial T2w scans covering the whole spinal cord. We investigated key factors influencing lesion segmentation, including the impact of stitching together individually acquired spinal regions, straightening the spinal cord, and comparing the effectiveness of 2D and 3D convolutional neural networks (CNNs). Drawing on these insights, we trained a multi-center model using an extensive dataset of 582 MS patients, resulting in a dataset comprising an entirety of 2,167 scans. We empirically evaluated the model‚Äôs segmentation performance across various spinal segments for lesions with varying sizes. Our model significantly outperforms the current state-of-the-art methods, providing consistent segmentation across cervical, thoracic, and lumbar regions. To support the broader research community, we integrate our model into the widely-used Spinal Cord Toolbox (v7.0 and above), making it accessible via the command sct_deepseg lesion_ms_axial_t2 -i &lt;path-to-image.nii.gz&gt;.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">karthik2025automatic</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Naga Karthik, Enamundram and McGinnis, Julian and Wurm, Ricarda and Ruehling, Sebastian and Graf, Robert and Valosek, Jan and Benveniste, Pierre-Louis and Lauerer, Markus and Talbott, Jason and Bakshi, Rohit and Tauhid, Shahamat and Shepherd, Timothy and Berthele, Achim and Zimmer, Claus and Hemmer, Bernhard and Rueckert, Daniel and Wiestler, Benedikt and Kirschke, Jan S. and Cohen-Adad, Julien and M√ºhlau, Mark}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic segmentation of spinal cord lesions in MS: A robust tool for axial T2-weighted MRI scans}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Imaging Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{IMAG.a.45}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2837-6056}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1162/IMAG.a.45}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1162/IMAG.a.45}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{*shared first authorship}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MedIA</abbr> <figure> <picture> <img src="/assets/img/publication_preview/contrast_agnostic_v2.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="contrast_agnostic_v2.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="BEDARD2025103473" class="col-sm-8"> <div class="title">Towards contrast-agnostic soft segmentation of the spinal cord</div> <div class="author"> Sandrine B√©dard<sup>*</sup>, Enamundram Naga Karthik<sup>*</sup>, Charidimos Tsagkas, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Emanuele Pravat√†, Cristina Granziera, Andrew Smith, Kenneth Arnold Weber II, Julien Cohen-Adad' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Medical Image Analysis</em>, Jun 2025 </div> <div class="periodical"> *shared first authorship </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.media.2025.103473" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S1361841525000210" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/sct-pipeline/contrast-agnostic-softseg-spinalcord" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=ZryIoMMAAAAJ&amp;citation_for_view=ZryIoMMAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Spinal cord segmentation is clinically relevant and is notably used to compute spinal cord cross-sectional area (CSA) for the diagnosis and monitoring of cord compression or neurodegenerative diseases such as multiple sclerosis. While several semi and automatic methods exist, one key limitation remains: the segmentation depends on the MRI contrast, resulting in different CSA across contrasts. This is partly due to the varying appearance of the boundary between the spinal cord and the cerebrospinal fluid that depends on the sequence and acquisition parameters. This contrast-sensitive CSA adds variability in multi-center studies where protocols can vary, reducing the sensitivity to detect subtle atrophies. Moreover, existing methods enhance the CSA variability by training one model per contrast, while also producing binary masks that do not account for partial volume effects. In this work, we present a deep learning-based method that produces soft segmentations of the spinal cord that are stable across MRI contrasts. Using the Spine Generic Public Database of healthy participants (n=267; contrasts=6), we first generated participant-wise soft ground truth (GT) by averaging the binary segmentations across all 6 contrasts. These soft GT, along with aggressive data augmentation and a regression-based loss function, were then used to train a U-Net model for spinal cord segmentation. We evaluated our model against state-of-the-art methods and performed ablation studies involving different GT mask types, loss functions, contrast-specific models and domain generalization methods. Our results show that using the soft average segmentations along with a regression loss function reduces CSA variability (p&lt;0.05, Wilcoxon signed-rank test). The proposed spinal cord segmentation model generalizes better than the state-of-the-art contrast-specific methods amongst unseen datasets, vendors, contrasts, and pathologies (compression, lesions), while accounting for partial volume effects. Our model is integrated into the Spinal Cord Toolbox (v6.2 and higher).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">BEDARD2025103473</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards contrast-agnostic soft segmentation of the spinal cord}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{101}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{103473}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1361-8415}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.media.2025.103473}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1361841525000210}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{B√©dard, Sandrine and Naga Karthik, Enamundram and Tsagkas, Charidimos and Pravat√†, Emanuele and Granziera, Cristina and Smith, Andrew and {Weber II}, Kenneth Arnold and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Spinal cord, MRI, Contrasts, Segmentation, Deep learning, Soft labels, Partial volume effect}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{*shared first authorship}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Radiology: AI</abbr> <figure> <picture> <img src="/assets/img/publication_preview/sciseg.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sciseg.jpeg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="doi:10.1148/ryai.240005" class="col-sm-8"> <div class="title">SCIseg: Automatic Segmentation of Intramedullary Lesions in Spinal Cord Injury on T2-weighted MRI Scans</div> <div class="author"> Enamundram Naga Karthik<sup>*</sup>, Jan Valo≈°ek<sup>*</sup>, Andrew C. Smith, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Dario Pfyffer, Simon Schading-Sassenhausen, Lynn Farner, Kenneth A. Weber, Patrick Freund, Julien Cohen-Adad' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Radiology: Artificial Intelligence</em>, Jun 2025 </div> <div class="periodical"> *shared first authorship </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1148/ryai.240005" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ivadomed/model_seg_sci/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=ZryIoMMAAAAJ&amp;citation_for_view=ZryIoMMAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Purpose: To develop a deep learning tool for the automatic segmentation of the spinal cord and intramedullary lesions in spinal cord injury (SCI) on T2-weighted MRI scans. Materials and Methods: This retrospective study included MRI data acquired between July 2002 and February 2023. The data consisted of T2-weighted MRI scans acquired using different scanner manufacturers with various image resolutions (isotropic and anisotropic) and orientations (axial and sagittal). Patients had different lesion etiologies (traumatic, ischemic, and hemorrhagic) and lesion locations across the cervical, thoracic, and lumbar spine. A deep learning model, SCIseg (which is open source and accessible through the Spinal Cord Toolbox, version 6.2 and above), was trained in a three-phase process involving active learning for the automatic segmentation of intramedullary SCI lesions and the spinal cord. The segmentations from the proposed model were visually and quantitatively compared with those from three other open-source methods (PropSeg, DeepSeg, and contrast-agnostic, all part of the Spinal Cord Toolbox). The Wilcoxon signed rank test was used to compare quantitative MRI biomarkers of SCI (lesion volume, lesion length, and maximal axial damage ratio) derived from the manual reference standard lesion masks and biomarkers obtained automatically with SCIseg segmentations. Results: The study included 191 patients with SCI (mean age, 48.1 years ¬± 17.9 [SD]; 142 [74%] male patients). SCIseg achieved a mean Dice score of 0.92 ¬± 0.07 and 0.61 ¬± 0.27 for spinal cord and SCI lesion segmentation, respectively. There was no evidence of a difference between lesion length (P = .42) and maximal axial damage ratio (P = .16) computed from manually annotated lesions and the lesion segmentations obtained using SCIseg. Conclusion: SCIseg accurately segmented intramedullary lesions on a diverse dataset of T2-weighted MRI scans and automatically extracted clinically relevant lesion characteristics. Keywords: Spinal Cord, Trauma, Segmentation, MR Imaging, Supervised Learning, Convolutional Neural Network (CNN) Published under a CC BY 4.0 license. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">doi:10.1148/ryai.240005</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Naga Karthik, Enamundram and Valo\v{s}ek, Jan and Smith, Andrew C. and Pfyffer, Dario and Schading-Sassenhausen, Simon and Farner, Lynn and Weber, Kenneth A. and Freund, Patrick and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SCIseg: Automatic Segmentation of Intramedullary Lesions in Spinal Cord Injury on T2-weighted MRI Scans}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Radiology: Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e240005}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{*shared first authorship}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MELBA</abbr> <figure> <picture> <img src="/assets/img/publication_preview/melba_uncertainty_softseg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="melba_uncertainty_softseg.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="melba:2022:031:lemay" class="col-sm-8"> <div class="title">Label fusion and training methods for reliable representation of inter-rater uncertainty</div> <div class="author"> Andreanne Lemay, Charley Gros, Enamundram Naga Karthik, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Julien Cohen-Adad' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Machine Learning for Biomedical Imaging</em>, Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.59275/j.melba.2022-db5c" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.melba-journal.org/pdf/2022:031.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=ZryIoMMAAAAJ&amp;citation_for_view=ZryIoMMAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Medical tasks are prone to inter-rater variability due to multiple factors such as image quality, professional experience and training, or guideline clarity. Training deep learning networks with annotations from multiple raters is a common practice that mitigates the model‚Äôs bias towards a single expert. Reliable models generating calibrated outputs and reflecting the inter-rater disagreement are key to the integration of artificial intelligence in clinical practice. Various methods exist to take into account different expert labels. We focus on comparing three label fusion methods: STAPLE, average of the rater‚Äôs segmentation, and random sampling of each rater‚Äôs segmentation during training. Each label fusion method is studied using both the conventional training framework and the recently published SoftSeg framework that limits information loss by treating the segmentation task as a regression. Our results, across 10 data splittings on two public datasets (spinal cord gray matter challenge, and multiple sclerosis brain lesion segmentation), indicate that SoftSeg models, regardless of the ground truth fusion method, had better calibration and preservation of the inter-rater rater variability compared with their conventional counterparts without impacting the segmentation performance. Conventional models, i.e., trained with a Dice loss, with binary inputs, and sigmoid/softmax final activate, were overconfident and underestimated the uncertainty associated with inter-rater variability. Conversely, fusing labels by averaging with the SoftSeg framework led to underconfident outputs and overestimation of the rater disagreement. In terms of segmentation performance, the best label fusion method was different for the two datasets studied, indicating this parameter might be task-dependent. However, SoftSeg had segmentation performance systematically superior or equal to the conventionally trained models and had the best calibration and preservation of the inter-rater variability. SoftSeg has a low computational cost and performed similarly in terms of uncertainty to ensembles which require multiple models and forward passes. Our code is available at https://ivadomed.org.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">melba:2022:031:lemay</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Label fusion and training methods for reliable representation of inter-rater uncertainty}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lemay, Andreanne and Gros, Charley and Naga Karthik, Enamundram and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning for Biomedical Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{January 2023 issue}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--27}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2766-905X}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.59275/j.melba.2022-db5c}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://melba-journal.org/2022:031}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%65%6D%76%6E%61%67%61%6B%61%72%74%68%69%6B@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/naga-karthik" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/naga-karthik-enamundram-7b1559174" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0003-2940-5514" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=ZryIoMMAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/naga_karthik7" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Interested in collaborating or just want to say hi? Drop me an email! </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Naga Karthik Enamundram. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. # Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>