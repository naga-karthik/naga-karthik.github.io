<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Enamundram Naga Karthik</title> <meta name="author" content="Enamundram Naga Karthik"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://naga-karthik.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">GitHub</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Enamundram</span> Naga Karthik </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> </div> </div> <div class="clearfix"> <p>Hi there! I‚Äôm Naga, a fourth-year PhD student at <a href="https://neuro.polymtl.ca" rel="external nofollow noopener" target="_blank">NeuroPoly</a>, Polytechnique Montr√©al. I‚Äôm also affiliated to <a href="https://mila.quebec/en" rel="external nofollow noopener" target="_blank">Mila - Qu√©bec AI Institute</a>. My research focuses on developing deep learning-based methods for medical image analysis, with a particular interest in spinal cord imaging using real-world clinical data. My current projects include contrast-agnostic segmentation of the spinal cord and the segmentation of lesions in spinal cord injury and multiple sclerosis (MS). I have also experimented with generative modelling, in particular, training GANs for cross-modality MR-CT synthesis and diffusion models for synthesizing spinal cord lesions. In the past, I have also worked on the application of continual/lifelong learning methods for the segmentation of brain MS lesions.</p> <p>When I am not working, you‚Äôll find me either running <img class="emoji" title=":running:" alt=":running:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c3.png" height="20" width="20">, hiking <img class="emoji" title=":mountain:" alt=":mountain:" src="https://github.githubassets.com/images/icons/emoji/unicode/26f0.png" height="20" width="20">, or reading <img class="emoji" title=":book:" alt=":book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png" height="20" width="20">.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Mar 13, 2025</th> <td> I was featured in the <a href="https://www.unique.quebec" rel="external nofollow noopener" target="_blank">UNIQUE-Qu√©bec</a> Newsletter as part of their student spotlight series! Please find the newsletter <a href="https://drive.google.com/file/d/1QAUg3TwfB2ygj8cFpwZACkK-9L18Z75C/view?usp=sharing" rel="external nofollow noopener" target="_blank">here</a>. üì∞ </td> </tr> <tr> <th scope="row">Jan 13, 2025</th> <td> Our paper ‚Äú<a href="https://www.sciencedirect.com/science/article/pii/S1361841525000210" rel="external nofollow noopener" target="_blank">Towards contrast-agnostic soft segmentation of the spinal cord</a>‚Äù was accepted at the Medical Image Analysis journal (Impact Factor: 10.7)! üéâ </td> </tr> <tr> <th scope="row">Jul 19, 2024</th> <td> Our paper ‚Äú<a href="https://arxiv.org/pdf/2407.17265" rel="external nofollow noopener" target="_blank">SCIsegV2: A Universal Tool for Segmentation of Intramedullary Lesions in Spinal Cord Injury</a>‚Äù was accepted at MICCAI Applications of Medical Artificial Intelligence (AMAI) Workshop 2024 in Marrakech, Morocco! üá≤üá¶ </td> </tr> <tr> <th scope="row">Apr 27, 2024</th> <td> Our spin-off project <a href="https://openreview.net/pdf?id=n6D25aqdV3" rel="external nofollow noopener" target="_blank">comparing different DL architectures for contrast-agnostic spinal cord segmentation</a> was accepted at the MIDL 2024 Short Paper Track! </td> </tr> <tr> <th scope="row">Mar 7, 2024</th> <td> I was awarded the <a href="https://www.daad-canada.ca/en/find-funding/graduate-opportunities/research-grants/short-term-research-grants/" rel="external nofollow noopener" target="_blank">DAAD Short-term Research Grant</a> for a 4-month research stay at the Technical University of Munich, Germany! ü•® üá©üá™ </td> </tr> <tr> <th scope="row">Feb 2, 2024</th> <td> Our recent works on contrast-agnostic spinal cord segmentation and segmentation of spinal cord injury lesions were accepted for Oral Presentations at the 2024 ISMRM &amp; ISMRT Annual Meeting &amp; Exhibition in Singapore <img class="emoji" title=":singapore:" alt=":singapore:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1f8-1f1ec.png" height="20" width="20"> ! </td> </tr> <tr> <th scope="row">Nov 22, 2023</th> <td> I gave a talk on Automatic Segmentation of Brain and Spinal Cord Lesions across Pathologies at the <a href="https://unique-students.github.io" rel="external nofollow noopener" target="_blank">UNIQUE Fellows Get-Together</a>, held at <a href="https://mila.quebec/en" rel="external nofollow noopener" target="_blank">Mila</a>! </td> </tr> <tr> <th scope="row">Aug 8, 2023</th> <td> I gave a talk on Continual Learning for Medical Image Segmentation at the <a href="https://chandar-lab.github.io/CRLSymposium/2023" rel="external nofollow noopener" target="_blank">Chandar Lab Symposium</a>, held at <a href="https://mila.quebec/en" rel="external nofollow noopener" target="_blank">Mila</a>! </td> </tr> <tr> <th scope="row">Jun 5, 2022</th> <td> Honoured to receive the <a href="https://www.gg.ca/en/honours/governor-generals-awards/governor-generals-academic-medal" rel="external nofollow noopener" target="_blank">Governor General of Canada‚Äôs Academic Gold Medal</a> for outstanding academic achievements during my master‚Äôs at √âTS! üèÖ üá®üá¶ </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Radiology: AI</abbr></div> <div id="doi:10.1148/ryai.240005" class="col-sm-8"> <div class="title">SCIseg: Automatic Segmentation of Intramedullary Lesions in Spinal Cord Injury on T2-weighted MRI Scans</div> <div class="author"> Enamundram Naga Karthik,¬†Jan Valo≈°ek,¬†Andrew C. Smith,¬†Dario Pfyffer,¬†Simon Schading-Sassenhausen,¬†Lynn Farner,¬†Kenneth A. Weber,¬†Patrick Freund,¬†and¬†Julien Cohen-Adad</div> <div class="periodical"> <em>Radiology: Artificial Intelligence</em>, 2025 </div> <div class="periodical"> *shared first authorship </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1148/ryai.240005" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ivadomed/model_seg_sci/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1148/ryai.240005"></span> <span class="__dimensions_badge_embed__" data-doi="10.1148/ryai.240005" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> Purpose: To develop a deep learning tool for the automatic segmentation of the spinal cord and intramedullary lesions in spinal cord injury (SCI) on T2-weighted MRI scans. Materials and Methods: This retrospective study included MRI data acquired between July 2002 and February 2023. The data consisted of T2-weighted MRI scans acquired using different scanner manufacturers with various image resolutions (isotropic and anisotropic) and orientations (axial and sagittal). Patients had different lesion etiologies (traumatic, ischemic, and hemorrhagic) and lesion locations across the cervical, thoracic, and lumbar spine. A deep learning model, SCIseg (which is open source and accessible through the Spinal Cord Toolbox, version 6.2 and above), was trained in a three-phase process involving active learning for the automatic segmentation of intramedullary SCI lesions and the spinal cord. The segmentations from the proposed model were visually and quantitatively compared with those from three other open-source methods (PropSeg, DeepSeg, and contrast-agnostic, all part of the Spinal Cord Toolbox). The Wilcoxon signed rank test was used to compare quantitative MRI biomarkers of SCI (lesion volume, lesion length, and maximal axial damage ratio) derived from the manual reference standard lesion masks and biomarkers obtained automatically with SCIseg segmentations. Results: The study included 191 patients with SCI (mean age, 48.1 years ¬± 17.9 [SD]; 142 [74%] male patients). SCIseg achieved a mean Dice score of 0.92 ¬± 0.07 and 0.61 ¬± 0.27 for spinal cord and SCI lesion segmentation, respectively. There was no evidence of a difference between lesion length (P = .42) and maximal axial damage ratio (P = .16) computed from manually annotated lesions and the lesion segmentations obtained using SCIseg. Conclusion: SCIseg accurately segmented intramedullary lesions on a diverse dataset of T2-weighted MRI scans and automatically extracted clinically relevant lesion characteristics. Keywords: Spinal Cord, Trauma, Segmentation, MR Imaging, Supervised Learning, Convolutional Neural Network (CNN) Published under a CC BY 4.0 license. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">doi:10.1148/ryai.240005</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Naga Karthik, Enamundram and Valo\v{s}ek, Jan and Smith, Andrew C. and Pfyffer, Dario and Schading-Sassenhausen, Simon and Farner, Lynn and Weber, Kenneth A. and Freund, Patrick and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SCIseg: Automatic Segmentation of Intramedullary Lesions in Spinal Cord Injury on T2-weighted MRI Scans}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Radiology: Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e240005}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1148/ryai.240005}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{*shared first authorship}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1148/ryai.240005}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MIDL Short</abbr></div> <div id="karthik2024contrastagnostic" class="col-sm-8"> <div class="title">Contrast-agnostic Spinal Cord Segmentation: A Comparative Study of ConvNets and Vision Transformers</div> <div class="author"> Enamundram Naga Karthik,¬†Sandrine Bedard,¬†Jan Valosek,¬†Sarath Chandar,¬†and¬†Julien Cohen-Adad</div> <div class="periodical"> <em>In Medical Imaging with Deep Learning</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=n6D25aqdV3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/sct-pipeline/contrast-agnostic-softseg-spinalcord/tree/nk/midl-short" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> The cross-sectional area (CSA) of the spinal cord (SC) computed from its segmentation is a relevant clinical biomarker for the diagnosis and monitoring of cord compression and atrophy. One key limitation of existing automatic methods is that their SC segmentations depend on the MRI contrast, resulting in different CSA across contrasts. Furthermore, these methods rely on CNNs, leaving a gap in the literature for exploring the performance of modern deep learning (DL) architectures. In this study, we extend our recent work \citeBdard2023TowardsCS by evaluating the contrast-agnostic SC segmentation capabilities of different classes of DL architectures, namely, ConvNeXt, vision transformers (ViTs), and hierarchical ViTs. We compared 7 different DL models using the open-source \textitSpine Generic Database of healthy participants () consisting of 6 MRI contrasts per participant. Given a fixed dataset size, our results show that CNNs produce robust SC segmentations across contrasts, followed by ConvNeXt, and hierarchical ViTs. This suggests that: (i) inductive biases such as learning hierarchical feature reprensentations via pooling (common in CNNs) are crucial for good performance on SC segmentation, and (ii) hierarchical ViTs that incorporate several CNN-based priors can perform similarly to pure CNN-based models. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">karthik2024contrastagnostic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Contrast-agnostic Spinal Cord Segmentation: A Comparative Study of ConvNets and Vision Transformers}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Karthik, Enamundram Naga and Bedard, Sandrine and Valosek, Jan and Chandar, Sarath and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Medical Imaging with Deep Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=n6D25aqdV3}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div id="b√©dard2023contrastagnostic" class="col-sm-8"> <div class="title">Towards contrast-agnostic soft segmentation of the spinal cord</div> <div class="author"> Sandrine B√©dard*,¬†<em>Naga Karthik Enamundram*</em>,¬†Charidimos Tsagkas,¬†Emanuele Pravat√†,¬†Cristina Granziera,¬†Andrew Smith,¬†Kenneth Arnold Weber II,¬†and¬†Julien Cohen-Adad</div> <div class="periodical"> 2023 </div> <div class="periodical"> *shared first authorship </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2310.15402.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/sct-pipeline/contrast-agnostic-softseg-spinalcord" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2310.15402"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">b√©dard2023contrastagnostic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards contrast-agnostic soft segmentation of the spinal cord}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{B√©dard*, Sandrine and Enamundram*, Naga Karthik and Tsagkas, Charidimos and Pravat√†, Emanuele and Granziera, Cristina and Smith, Andrew and II, Kenneth Arnold Weber and Cohen-Adad, Julien}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2310.15402}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{eess.IV}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{*shared first authorship}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%65%6D%76%6E%61%67%61%6B%61%72%74%68%69%6B@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-2940-5514" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=ZryIoMMAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/naga-karthik" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/naga-karthik-enamundram-7b1559174" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/naga_karthik7" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> Interested in collaborating or just want to say hi? Drop me an email! </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Enamundram Naga Karthik. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: March 14, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-2GT79X63MT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-2GT79X63MT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>