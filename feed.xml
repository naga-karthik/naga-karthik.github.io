<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://naga-karthik.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://naga-karthik.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-17T18:49:26+00:00</updated><id>https://naga-karthik.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">What Statistical Tests Should I Perform?</title><link href="https://naga-karthik.github.io/blog/2025/what-statistical-tests/" rel="alternate" type="text/html" title="What Statistical Tests Should I Perform?"/><published>2025-09-15T00:00:00+00:00</published><updated>2025-09-15T00:00:00+00:00</updated><id>https://naga-karthik.github.io/blog/2025/what-statistical-tests</id><content type="html" xml:base="https://naga-karthik.github.io/blog/2025/what-statistical-tests/"><![CDATA[<p>Too often, I see tables in ML papers where authors claim that their method is “significantly” better than the rest of the methods without performing any statistical tests. I feel that such claims should be backed up by statistical evidence and not just concluding from the magnitude of the metrics reported. Even if the error intervals are reported, the top methods tend to lie with the standard deviation of each other, making it hard to conclude which method is <em>actually</em> better. Therefore, in this post, I intend to cover a few recurring scenarios when presenting results in ML papers and what kind of tests could be performed. Choosing the right test is tricky but it is worth the effort as results backed by statistical evidence seem more credible. This post is inspired from my own struggles in deciding what tests to do and how I wished there was a guide for non-stats folks to refer to when it’s time to put results into the paper.</p> <p>Here’s a flowchart on the most common types of tests depending on the type of the output variable followed by the series of tests to consider.</p> <d-figure> <img src="/assets/img/blog_pictures/stats/stats_tests_flowchart.svg" alt="A flowchart for choosing the right statistical test." class="img-fluid rounded"/> <figcaption style="text-align: center;"> A flowchart for choosing the right statistical test. Adapted from <a href="https://www.med.soton.ac.uk/resmethods/statisticalnotes/which_test_flow.htm" target="_blank">this source</a>. </figcaption> </d-figure> <h3 id="definitions">Definitions</h3> <h4 id="outcome-dependent-variable-types">Outcome (dependent) variable types</h4> <ul> <li><strong>Continuous variables</strong>: Think measuring tape. Continuous variables represent values that can be measured on a continuous scale. Their values are not restricted to separate, distinct numbers. For example: <ul> <li>Performance metrics such as the F1-score, MSE; values whose range lies between 0-1.</li> <li>Features such as a person’s height, average temperature, etc.</li> </ul> </li> <li><strong>Categorical variables</strong>: Think groups or labeled buckets. Categorical variables only take on a limited set of values, assigning each data point to a particular group. There are two types of variables: (i) <strong>Nominal</strong>: categories have <em>no</em> intrinsic order (e.g. car, bus, plane), and (ii) <strong>Ordinal</strong>: categories have a meaniningful order (e.g. rating something as <code class="language-plaintext highlighter-rouge">good</code>, <code class="language-plaintext highlighter-rouge">okay</code>, <code class="language-plaintext highlighter-rouge">bad</code>, or, levels of difficulty, etc.). A few examples of categorial variables: <ul> <li>Model prediction as <code class="language-plaintext highlighter-rouge">Spam</code>/<code class="language-plaintext highlighter-rouge">Not spam</code>, or, classification of a bacterium as <code class="language-plaintext highlighter-rouge">Resistant</code>/<code class="language-plaintext highlighter-rouge">Susceptible</code> against a specific antibiotic.</li> <li>Features such as grading of a tumor on a scale of 1-4 (note: this is ordinal), or, a person’s blood type (A, B, AB, O; note: this is nominal).</li> </ul> </li> <li><strong>Survival variables</strong>: Think an hourglass. A survival variable is a unique type of data that has two parts: (i) a measure of time until a specific event occurs, and (ii) an indicator of whether the event has occurred or if the observation period ended before the event could happen (this is called censoring). A few examples: <ul> <li>Time until a patient relapses after treatment, with some patients still being disease-free at the end of the study (censored data).</li> <li>Time until a machine fails, with some machines still operational at the end of the observation period (censored data).</li> </ul> </li> </ul> <h4 id="exposure-independent-variable-types">Exposure (independent) variable types</h4> <ul> <li> <p><strong>Groups</strong>: They refer to the different methods/models we want to compare. For example, if we have three models A, B, and C, then we have three “groups”.</p> </li> <li> <p><strong>Samples</strong>: They refer to the number of observations we have for each group. For example, (i) each set of predictions from models A, B, and C is a sample (so three models, three sets of samples), (ii) if we have five different runs of model A, then we have five samples for model A, and so on.</p> </li> <li> <p><strong>Paired samples</strong>: They refer to the samples that are related to each other. For example, (i) if we have three models A, B, and C and we evaluate them on the same test set, then the samples from these models are “paired” because they are related to each other through the same test set, (ii) if we have a model that we run five times with different random seeds and evaluate them on the same test set, then the samples from these five runs are paired samples.</p> </li> <li> <p><strong>Independent samples</strong>: They refer to the samples that are <em>not</em> related to each other. For example, say we have a large test dataset and we create non-overlapping sub-test sets from it. Then, evaluating models A, B, and C on these different sub-test sets will give us independent samples.</p> </li> <li> <p><strong>Parametric</strong>: This class of tests assume that the data follows some “known” distribution (most commonly the normal distribution) and are based on the parameters like the mean and standard deviation. Normality of the data can be tested using D’Agostino and Pearson’s test, Shapiro-Wilk test, etc. If the p-value from these tests is greater than a significance level (typically 0.05), meaning that the null hypothesis ($H_0$; stating that the data is normally distributed) is <em>not</em> rejected. This implies that we don’t have enough evidence to conclude that the data are not normally distributed, but know that the data lack a significant deviation from the normal distribution (hence enabling the use of parametric tests).</p> </li> <li> <p><strong>Non-parametric</strong>: This class of tests do not assume that the data follow a normal distribution. They are typically used when the data is not normally distributed or when the sample size is small (typically less than 30 per group).</p> </li> </ul> <p><a href="https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/">Statistics How To</a> is more extensive in terms of the definitions covered. Do check it out!</p> <h4 id="errors-in-hypothesis-testing">Errors in hypothesis testing</h4> <p>When performing statistical tests, we typically start with a null hypothesis ($H_0$) and an alternative hypothesis ($H_a$). The null hypothesis usually states that there is no effect or no difference between the groups, while the alternative hypothesis states that there is an effect or a difference. Based on the results of the statistical test, we either reject the null hypothesis or fail to reject it. However, there are two types of errors that can occur in this process:</p> <ul> <li> <p><strong>Type I error (False Positive)</strong>: It occurs when we reject the null hypothesis ($H_0$) when it is actually true. In simpler terms, it’s like a false alarm where we think there is an effect or difference when there isn’t one (e.g. concluding that a drug is effective when it’s not). The significance level (alpha, typically set at 0.05) represents the probability of making a Type I error. For example, if we set alpha to 0.05, it means that we are willing to accept a 5% chance of incorrectly rejecting the null hypothesis.</p> </li> <li> <p><strong>Type II error (False Negative)</strong>: It occurs when we fail to reject the null hypothesis ($H_0$) when it is actually false. In simpler terms, it’s like missing a real effect or difference that actually exists (e.g. failing to detect that a drug is working). The probability of making a Type II error is denoted by beta (β). The power of a test, which is calculated as (1 - β), represents the probability of correctly rejecting the null hypothesis when it is false. A higher power means a lower chance of making a Type II error. Typically, researchers aim for a power of 0.8 or higher, meaning there is an 80% chance of correctly detecting an effect if it exists.</p> </li> </ul> <h3 id="choosing-the-right-test">Choosing the right test</h3> <p>When it comes to presenting the results, a recurring scenario is the following:</p> <blockquote> <p>We have the method/model that we have proposed and we want to compare its performance with the rest of the methods/models from the literature. We also have a fixed test set on which we evaluate our models on.</p> </blockquote> <p>Now, let’s take a bottom-up approach to arrive at the right test(s) to perform. Note that the test set is fixed so we have already reduced the search space for the class of the tests to be within: “2 groups” or “&gt;2 groups” with “paired” samples (since the models are evaluated on the same test set). If we have two models (model A vs. model B) then we use either paired Student’s t-test or Wilcoxon signed rank test if the variable we want to compare is continuous (e.g. accuracy, F1-score, etc.) and McNemar’s test if the variable is categorical (e.g. model predictions as <code class="language-plaintext highlighter-rouge">Spam</code>/<code class="language-plaintext highlighter-rouge">Not spam</code>). If we’re comparing more than two models (i.e. ours and two or more) then we use either repeated measures ANOVA or Friedman test if the variable we want to compare is continuous and Cochran’s Q test if the variable is categorical. The next natural question is: should we use parametric or non-parametric tests?</p> <h4 id="parametric-or-non-parametric">Parametric or Non-parametric?</h4> <p>When comparing continuous variables, the choice between choosing parametric or non-parametric tests depends on the distribution of the data. To ground it in ML terms, the “data” here refer to the set of performance metrics on the test set obtained from the models we want to compare. To know how the data are distributed we typically run normality tests from the <code class="language-plaintext highlighter-rouge">scipy.stats</code> package. Here’s a short code example of how to do it:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="c1"># Example data: performance metrics from two models
</span><span class="n">model_a_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.88</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">])</span>
<span class="n">model_b_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.79</span><span class="p">])</span>
<span class="c1"># Perform D'Agostino and Pearson's test for normality
</span><span class="n">stat_a</span><span class="p">,</span> <span class="n">p_value_a</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">normaltest</span><span class="p">(</span><span class="n">model_a_metrics</span><span class="p">)</span>
<span class="n">stat_b</span><span class="p">,</span> <span class="n">p_value_b</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">normaltest</span><span class="p">(</span><span class="n">model_b_metrics</span><span class="p">)</span>
<span class="c1"># Significance level
# NOTE: The null hypothesis (H0) is that the data is normally distributed.
</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="c1"># Check if the data is normally distributed
</span><span class="n">is_a_normal</span> <span class="o">=</span> <span class="n">p_value_a</span> <span class="o">&gt;</span> <span class="n">alpha</span>
<span class="n">is_b_normal</span> <span class="o">=</span> <span class="n">p_value_b</span> <span class="o">&gt;</span> <span class="n">alpha</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model A normality: </span><span class="si">{</span><span class="n">is_a_normal</span><span class="si">}</span><span class="s">, p-value: </span><span class="si">{</span><span class="n">p_value_a</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model B normality: </span><span class="si">{</span><span class="n">is_b_normal</span><span class="si">}</span><span class="s">, p-value: </span><span class="si">{</span><span class="n">p_value_b</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># CHECK
# If p &gt; alpha, we fail to reject the null hypothesis --&gt; data is normally distributed --&gt; parametric
# If p &lt;= alpha, we reject the null hypothesis --&gt; data is not normally distributed --&gt; non-parametric
</span></code></pre></div></div> <p>Based on the normality tests, we now know whether to choose from parametric or non-parametric tests. More detailed definitions with examples can be found <a href="https://www.mayo.edu/research/documents/parametric-and-nonparametric-demystifying-the-terms/doc-20408960">here</a>. Continuing the example from the scenario mentioned above, say there are more than 2 groups (i.e. we’re comparing more than 2 methods) and the test indicates that there is a significant difference between the groups. How do we know which groups are different from each other? This is where post-hoc tests come into play.</p> <h4 id="post-hoc-tests">Post-hoc tests</h4> <p><em>Post-hoc</em> is a Latin term that means “after this”. <a href="https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/post-hoc/">Post-hoc tests</a> are additional tests performed after an initial statistical test (like ANOVA or Friedman test) to determine which specific groups are different from each other. They help to identify where the differences lie when the initial test indicates that there is a significant difference among the groups. More concretely, say we have three models A, B, and C and we perform a Friedman test (non-parametric) to compare their performance on a fixed test set. The test gives a p-value of 0.02 (which is significant!). But, we don’t know which pairs of models are significantly different from each other (i.e. A vs. B, A vs. C, B vs. C). Therefore, we perform post-hoc tests, which involve multiple pairwise comparisons between the groups to identify which specific pairs of groups have significant differences in their means or distributions. Some common post-hoc tests include:</p> <ul> <li><strong>Tukey’s HSD (Honestly Significant Difference) test</strong>: used after ANOVA to find means that are significantly different from each other.</li> <li><strong>Bonferroni correction</strong>: adjusts the significance level when multiple pairwise tests are performed to control the overall Type I error rate. This correction limits the possibility of getting a statistically significant result because, the more tests we run, the more likely we are to get a significant result. The correction essentially lowers the area where we can reject the null hypothesis by adjusting the alpha according to the number of tests. For e.g. after Bonferroni correction, \(\alpha_{\textrm{new}} = \alpha_{\textrm{old}} / N\), where $N$ is the number of tests or number of comparisons.</li> <li><strong>Dunn’s test</strong>: non-parametric post-hoc test used after the Kruskal-Wallis test or Friedman test.</li> </ul> <p>Here’s a short code example on performing Dunn’s post-hoc test:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">scikit_posthocs</span> <span class="k">as</span> <span class="n">sp</span>
<span class="c1"># Example data: performance metrics from three models
</span><span class="n">model_a_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.88</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">])</span>
<span class="n">model_b_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.79</span><span class="p">])</span>
<span class="n">model_c_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.78</span><span class="p">,</span> <span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.79</span><span class="p">,</span> <span class="mf">0.76</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">])</span>
<span class="c1"># Combine the data into a single array
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">model_a_metrics</span><span class="p">,</span> <span class="n">model_b_metrics</span><span class="p">,</span> <span class="n">model_c_metrics</span><span class="p">])</span>
<span class="c1"># Create a group labels array
</span><span class="n">groups</span> <span class="o">=</span> <span class="p">([</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">model_a_metrics</span><span class="p">)</span> <span class="o">+</span>
          <span class="p">[</span><span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">model_b_metrics</span><span class="p">)</span> <span class="o">+</span>
          <span class="p">[</span><span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">model_c_metrics</span><span class="p">))</span>
<span class="c1"># Create a DataFrame for the data
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">Model</span><span class="sh">'</span><span class="p">:</span> <span class="n">groups</span><span class="p">,</span> <span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="n">data</span><span class="p">})</span>
<span class="c1"># Perform Dunn's test with Holm-Bonferroni correction
</span><span class="n">dunn_results</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">posthoc_dunn</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">val_col</span><span class="o">=</span><span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="n">group_col</span><span class="o">=</span><span class="sh">'</span><span class="s">Model</span><span class="sh">'</span><span class="p">,</span> <span class="n">p_adjust</span><span class="o">=</span><span class="sh">'</span><span class="s">holm</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dunn_results</span><span class="p">)</span>
</code></pre></div></div> <p>Note that post-hoc tests are only performed when the initial test indicates that there is a significant difference between the groups.</p> <p>Okay, we now have an understanding of how to go about choosing the right test. Let’s look at a few examples now.</p> <h3 id="examples">Examples</h3> <h4 id="example-1-comparing-accuracy-between-five-models-on-a-fixed-test-set">Example 1: Comparing accuracy between five models on a fixed test set</h4> <p>Say you have five models (A, B, C, D, E) and you want to compare their accuracy on a fixed test set. The workflow would be as follows:</p> <ol> <li>Since we’re comparing accuracy, the outcome variable is continuous.</li> <li>We have five models, so we have more than two groups.</li> <li>The samples are paired since the models are evaluated on the same test set.</li> <li>Check for normality on each of the test set predictions for the five models. If all the models’ predictions are normally distributed, we can use parametric tests. If at least one of them is not normally distributed, we use non-parametric tests.</li> <li>Choose the appropriate test. So, we have: <ul> <li><code class="language-plaintext highlighter-rouge">continuous</code>, <code class="language-plaintext highlighter-rouge">&gt;2 groups</code>, <code class="language-plaintext highlighter-rouge">paired</code>, <code class="language-plaintext highlighter-rouge">non-parametric</code>: Friedman test</li> <li><code class="language-plaintext highlighter-rouge">continuous</code>, <code class="language-plaintext highlighter-rouge">&gt;2 groups</code>, <code class="language-plaintext highlighter-rouge">paired</code>, <code class="language-plaintext highlighter-rouge">parametric</code>: Repeated measures ANOVA</li> </ul> </li> <li>If the test indicates that there is a significant difference between the groups, perform post-hoc test. For <code class="language-plaintext highlighter-rouge">parametric</code>, use Tukey’s HSD test. For <code class="language-plaintext highlighter-rouge">non-parametric</code>, use Dunn’s test.</li> </ol> <h4 id="example-2-comparing-ages-of-patients-in-train-and-test-sets">Example 2: Comparing ages of patients in train and test sets</h4> <p>Say you are working with medical data and you have randomly split the data into train/test but you want to know if the age of the patients in train set is significantly different from that in the test set (to make a case for your model’s generalization across age groups). The workflow would be as follows:</p> <ol> <li>Identify the type of outcome variable: <code class="language-plaintext highlighter-rouge">Age</code> is a continuous variable.</li> <li>Identify the number of groups: We have two groups (train and test).</li> <li>Identify the type of samples: The samples are independent since the train and test sets are disjoint.</li> <li>Check for normality: Use D’Agostino and Pearson’s test or Shapiro-Wilk test to check if the age data in both groups is normally distributed.</li> <li>Choose the appropriate test: <ul> <li><code class="language-plaintext highlighter-rouge">continuous</code>, <code class="language-plaintext highlighter-rouge">2 groups</code>, <code class="language-plaintext highlighter-rouge">independent</code>, <code class="language-plaintext highlighter-rouge">non-parametric</code>: Mann-Whitney U test</li> <li><code class="language-plaintext highlighter-rouge">continuous</code>, <code class="language-plaintext highlighter-rouge">2 groups</code>, <code class="language-plaintext highlighter-rouge">independent</code>, <code class="language-plaintext highlighter-rouge">parametric</code>: Student’s t-test (two-sample t-test)</li> </ul> </li> </ol> <h4 id="example-3-comparing-model-predictions-categorical-between-three-models-on-a-fixed-test-set">Example 3: Comparing model predictions (categorical) between three models on a fixed test set</h4> <p>Say you have three models (A, B, C) and you want to compare their predictions (as <code class="language-plaintext highlighter-rouge">Malignant</code>/<code class="language-plaintext highlighter-rouge">Benign</code>) on a fixed test set. The workflow would be as follows:</p> <ol> <li>Since we’re comparing models’ binary classification predictions, the outcome variable is categorical.</li> <li>We have three models, so we have more than two groups.</li> <li>The samples are paired since the models are evaluated on the same test set.</li> <li>Choose the appropriate test. So, we have: <ul> <li><code class="language-plaintext highlighter-rouge">categorical</code>, <code class="language-plaintext highlighter-rouge">&gt;2 groups</code>, <code class="language-plaintext highlighter-rouge">paired</code>: Cochran’s Q test</li> </ul> </li> </ol> <h3 id="general-notes-and-common-pitfalls">General Notes and Common Pitfalls</h3> <h4 id="choosing-significance-level-alpha">Choosing significance level (alpha)</h4> <p>A good significance level balances the risks of false positives and false negatives. Choosing the right significance level depends on the context and the consequence of the errors. A significance level of 5% is more commonly used than that of 1% which is more conservative and used only in safety-critical applications like medicine.</p> <h4 id="ignoring-the-multiple-comparisons-problem">Ignoring the multiple comparisons problem</h4> <p>When we have 3 or more groups to compare, running multiple pairwise tests (i.e. A vs. B, A vs. C, B vs. C) should <em>not</em> be done as multiple comparisons increase the chance of getting a “significant” result purely by luck. As each test has its own significance level (alpha), the overall chance of getting a false positive increases with multiple comparisons. Therefore, in this scenario, it is recommended to run a Friedman test or repeated measures ANOVA, and if it is significant, then only run post hoc tests to find specific differences between groups.</p> <p>I only focused on examples of contiguous and categorical variables in this post because those are what I came across most often. I will update this post with examples of survival variables and their tests in the future.</p> <p>Thanks to Kalum Ost, Jan Valošek, Pierre-Louis Benveniste, and Gemini 2.5 Pro for their suggestions on the drafts of this post.</p>]]></content><author><name></name></author><category term="resources"/><category term="statistics"/><summary type="html"><![CDATA[A guide to choosing the right statistical tests for your next paper.]]></summary></entry><entry><title type="html">Keeping up with research</title><link href="https://naga-karthik.github.io/blog/2023/managing-research/" rel="alternate" type="text/html" title="Keeping up with research"/><published>2023-09-11T23:00:00+00:00</published><updated>2023-09-11T23:00:00+00:00</updated><id>https://naga-karthik.github.io/blog/2023/managing-research</id><content type="html" xml:base="https://naga-karthik.github.io/blog/2023/managing-research/"><![CDATA[<p>It depends on which field you are in but if you are a graduate student in machine learning (ML), a thought that would have crossed your mind is - <em>How do I keep up with this enormous volume of research</em>? Thousands of papers get uploaded to ArXiv every day and every other week there’s a new open-source large language model released by a big tech company. Because I work in ML, the analogies I draw will be related to ML but the general advice on <em>how to read</em> could be applied to any field (not only for research papers but books too).</p> <p>As a disclaimer, note that everyone has to come with up their own way of reading and coping with the literature so take what follows with a grain of salt.</p> <p>I recently came across an <a href="https://collabfund.com/blog/how-to-read-lots-of-inputs-and-a-strong-filter/">article</a> by Morgan Housel that essentially said that a good strategy for reading [books] is to take lots of inputs, inundate yourself with information, but have a strong filter to retain what’s best. I have been an avid reader of his work which gives a great outsider perspective on finance and investing, with examples from history that withstood the test of time. Simply put, his articles are short, incisive, fun to read, and always leave you with something more to think about.</p> <p>Starting with books, it often so happens that we start reading a book and when it seems that it is not interesting anymore, we tend to push through just so that we can tell ourselves that we have <em>finished</em> it. I have been guilty of this numerous times. This is the way we have been taught to approach reading in school so it is innate in that sense. But, some really smart people do not follow this norm. For example, Charlie Munger does not go beyond the first chapter, Naval Ravikant <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/learn-to-love-to-read">skims and jumps around</a> different chapters. Neither of them carries the “burden” of not getting through a book.</p> <p><strong>But why should you read more?</strong>   This is a question that I have myself asked and been fascinated by the answer. It all started to make sense. First, when you go through the books of the same genre that you’re comfortable with and know what to expect (like reading research papers in your field), you limit the ability to connect the dots across different fields. Secondly, when you increase your bandwidth and let new ideas in, you also increase the chances of finding that idea (or, set of ideas) that might have a great application in your field. In purely ML terms, supposing that each neuron is an idea that you’ve come across, by increasing the width of your neural network, you are essentially setting the stage for those <a href="https://arxiv.org/abs/1803.03635">lottery ticket</a> neurons (ideas) that would be just enough to solve your problem. Another great example comes from the history of mankind as put forth by Matt Ridley in his book <a href="https://www.goodreads.com/cs/book/show/7776209">The Rational Optimist</a>. The point here is that true innovations, i.e. the innovations that have a significant impact on the world, are the combination and recombination of several existing ideas.</p> <p><strong>Need for a filter</strong>   Our brains have finite capacity, so a strong/narrow filter is crucial after absorbing a lot of information. It is here that one has to be ruthless in terms of what’s retained. For research papers, if you find yourself going over an introductory paragraph or an abstract multiple times to understand what the contribution or what the paper is trying to say, save yourself some time and move on. Lots of fish in the sea. Unless you’re trying to reproduce a paper, go through the paper superficially and try to extract its main idea. Practically, this means getting a high-level understanding of the paper such that it can be explained in a few sentences.</p> <p>It is important to understand that training your filter in a slew of research papers takes time and effort. But, the better your filter gets, the easier it is to get the gist of the paper(s), and eventually mix and match them to get a creative, novel idea. The importance of reading more and having a good filter can be summarized below as Housel does in his article:</p> <blockquote> <p>Without flooding your brain with inputs you’ll be stuck in the tiny world of what you’ve personally experienced. But without a strong filter, you’ll be overwhelmed with choice and paralyzed by inaction.</p> </blockquote> <p><strong>Okay so how can I do it?</strong>   As mentioned before, everyone has to come up with an approach that works best for them. I am going to briefly describe the approach I am taking to keep up with the research in my field. As a note, what I am going to describe is a miniature version of <a href="https://www.nature.com/articles/d41586-022-01878-7">this post</a> by Maya Gosztyla. And, I will only focus on the “finding” part as there are several articles out there explaining how to read and organize literature that do a much better job.</p> <p>A classical way to get the relevant literature delivered to your inbox is by signing up for <a href="https://www.nihlibrary.nih.gov/resources/subject-guides/keeping-current/creating-alerts-google-scholar">keyword alerts on Google Scholar</a> or alerts from the impactful journals in your field. If you are taking this route, make sure that you have these alerts categorized into labels in your inbox so that it doesn’t get flooded.</p> <p>In addition to that (and this is what helped me the most), subscribing to RSS feeds and using a feed aggregator app is a great way to pool all the relevant literature. <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> (<em>Really Simple Syndication</em>) is a web feed that allows users/applications to access updates to websites in real-time. ArXiv has its own RSS feed for each category as does every major journal. <a href="https://feedly.com">Feedly</a> is a great RSS feed aggregator that allows you to have up to three folders with the free version and you can add as many RSS feeds within these folders. Important papers can also be saved by adding them to the “Read Later” board. Some examples of RSS feeds:</p> <ul> <li>Machine Learning (cs.LG) on ArXiv - <a href="http://arxiv.org/rss/cs.CV">http://arxiv.org/rss/cs.CV</a></li> <li>Image and Video Processing (eess.IV) - <a href="http://arxiv.org/rss/eess.IV">http://arxiv.org/rss/eess.IV</a></li> <li>Elsevier’s Medical Image Analysis - <a href="http://rss.sciencedirect.com/publication/science/13618415">http://rss.sciencedirect.com/publication/science/13618415</a></li> </ul> <p>One of the good features of Feedly is that you don’t have to “find” the exact RSS feed link. Its search function already has a good collection of RSS feeds that can be easily subscribed to. In my personal experience, I have found that subscribing to relevant feeds (like the ones above) automatically brings the latest literature and I just have to set some time aside to go through them. It’s just convenient.</p> <p>It can be challenging to keep up with the vast amount of literature currently being produced. I hope that this post has left you with something to think about reading. Good luck with your research!</p>]]></content><author><name></name></author><category term="resources"/><category term="research"/><summary type="html"><![CDATA[Insights on reading and managing the literature]]></summary></entry><entry><title type="html">Getting started with machine learning and neuroimaging</title><link href="https://naga-karthik.github.io/blog/2023/resources-ml-and-neuroimaging/" rel="alternate" type="text/html" title="Getting started with machine learning and neuroimaging"/><published>2023-08-20T17:16:00+00:00</published><updated>2023-08-20T17:16:00+00:00</updated><id>https://naga-karthik.github.io/blog/2023/resources-ml-and-neuroimaging</id><content type="html" xml:base="https://naga-karthik.github.io/blog/2023/resources-ml-and-neuroimaging/"><![CDATA[<p>This summer I had the privilege of mentoring a CÉGEP student whose goal for the summer, to quote, was to “learn the basics of machine learning and get an overview of how your (PhD) projects look like before my undergrad starts”. Hence, I decided to come up with a short curriculum that goes from the very basic concepts of math and programming to some applications of machine learning on real-world data. Before going further, a <em>CÉGEP</em> is a college offering a mix of programs (both technical and non-technical) that is exclusive to Quebec’s education system. Typically two years in duration, it is seen as an important step towards proper academic preparation to succeed at university.</p> <p>As for the curriculum, I put together a <a href="https://docs.google.com/document/d/1hwtH3kPJYypE88Fs-X3NYnJVc8rI8f2-CgQ2xPJEZu0/edit">Google Doc</a> that contains the list of resources that I believe are helpful for anyone looking to learn the fundamentals of machine learning. The content is divided across 10 weeks with a predefined set of milestones for each week. Please note that this document was prepared with comprehension level of post-secondary student in mind. Hence, during the initial weeks, we cover the fundamentals of math and Python programming required for machine learning and gradually move towards the basics of neuroimaging. We chose neuroimaging for two main reasons, one, the student wanted to get a headstart on neuroimage analysis, and second, it acts as a good test-bed for applying the ML concepts learned during the initial weeks on real-world data.</p> <p>A few highlights of what the Doc covers:</p> <ol> <li><strong>Math</strong> - Linear Algebra, Analytic Geometry, Single variable and Multivariable Calculus, Probability, etc.</li> <li><strong>Programming</strong> - Introduction to Python, Python Classes and Data Structures, Sorting and Searching, etc.</li> <li><strong>Git</strong> - Introduction to Version Control, Git Branching, GitHub Basics, etc.</li> <li><strong>Machine Learning</strong> - Linear/Logistic Regression, SVMs, Gradient Descent, Backpropagation</li> <li><strong>Neuroimaging</strong> - Data and File Structures, Neuroimaging in Python, BIDS Convention, etc.</li> </ol> <p>While deciding on the topics for each week, I have found myself repeatedly going back to a few resources, which I wanted to highlight separately:</p> <ol> <li><a href="https://mml-book.github.io/book/mml-book.pdf">Mathematics for Machine Learning</a> Textbook</li> <li><a href="https://runestone.academy/ns/books/published//pythonds/index.html">Problem Solving with Algorithms and Data Structures using Python</a> - I have gone through a few chapters of this book and it really presents the concepts in a brief, fun way with hands-on exercises. All the chapters are highly relevant for learning/revising Python concepts.</li> <li><a href="https://www.youtube.com/watch?v=jGwO_UgTS7I&amp;list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU">CS229: Machine Learning</a> - YouTube lecture series of Stanford’s famous ML course taught by Andrew Ng.</li> </ol> <p>This was just an overview of the contents inside the Doc. There are several useful videos, tutorials, blog posts, etc. which I highly encourage you to check out! Happy learning!</p>]]></content><author><name></name></author><category term="resources"/><category term="math"/><category term="machine-learning"/><summary type="html"><![CDATA[Some useful resources for getting started with machine learning and neuroimaging.]]></summary></entry><entry><title type="html">List of Books I Read in 2020</title><link href="https://naga-karthik.github.io/blog/2023/books-in-2020/" rel="alternate" type="text/html" title="List of Books I Read in 2020"/><published>2023-08-08T22:27:00+00:00</published><updated>2023-08-08T22:27:00+00:00</updated><id>https://naga-karthik.github.io/blog/2023/books-in-2020</id><content type="html" xml:base="https://naga-karthik.github.io/blog/2023/books-in-2020/"><![CDATA[<p>This is a new initiative of mine, where I list the books that I have read in year <em>X</em> and also mention the book that I’m currently reading. This post also comes after a long break and I hope to start blogging regularly (as you can see I am already 2 years behind).</p> <p>Alright, it’s 2020, we’re in the early stages of the pandemic and are confined to our homes. I lost the habit of reading during my undergrad so I finally thought of getting some reading done.</p> <p>A brief bit of context for the type of books you’ll see below - I always was interested in human psychology (still am) and had also started thinking about investing. I was reading books independently out of these two categories, until I stumbled upon this sub-field in economics called behavioral economics. In short, as the name suggests, it combines the fields classical economics and psychology in order to understand why humans make certain choices/decisions (in other words, understand why humans do what they do) in investing, and more broadly, in life. This, therefore, ended up defining the trajectory for some of the the books I would be reading for the year.</p> <ol> <li><a href="https://www.amazon.ca/Think-Grow-Rich-Million-Dollars/dp/0449214923/ref=tmm_mmp_swatch_0?_encoding=UTF8&amp;qid=1660424686&amp;sr=1-1">Think and Grow Rich</a> - Napolean Hill</li> <li><a href="https://www.goodreads.com/book/show/68984.The_Power_of_Your_Subconscious_Mind?ref=nav_sb_ss_1_16">The Power of your Subconscious Mind</a> - Dr. Joseph Murphy <ul> <li>More of a self-help than psychology, the book gives some amazing insights into our subconscious mind and how we can <em>condition</em> it to achieve our goals.</li> </ul> </li> <li><a href="https://www.amazon.ca/Atomic-Habits-Proven-Build-Break/dp/0735211299/ref=sr_1_1?keywords=atomic+habits&amp;qid=1660425763&amp;s=books&amp;sprefix=ato%2Cstripbooks%2C128&amp;sr=1-1">Atomic Habits</a> - James Clear <ul> <li>I don’t think I have ever seen this book <em>outside of</em> Amazon Charts</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/1202.Freakonomics?ref=nav_sb_ss_1_5">Freakonomics</a> - Steven Dubner and Stephen Levitte <ul> <li>While the book is definitely a fun read, Steven Dubner also has a podcast series <a href="https://freakonomics.com/series/freakonomics-radio/">Freakonomics Radio</a> that continues discussing the questions that we usually take for granted (or not).</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/26530355-misbehaving?ref=nav_sb_noss_l_7">Misbehaving, the making of Behavioral Economics</a> - Richard Thaler <ul> <li><em>The book</em> that I would recommed for anyone interested in this sub-field of economics.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/3450744-nudge?ref=nav_sb_ss_1_5">Nudge: Improving Decisions about Health, Wealth, and Happiness</a> - Richard Thaler and Cass Sunstein <ul> <li>Since I loved Thaler’s style of writing, I decided to read this. As aptly said in the title, it is amazing how simple nudges in the right direction, can go a long way in cultivating a better life. This is precisely one of the reasons I am interested in behavioral economics - it brings forth the subtleties of human behaviour that would otherwise be hard to observe in the (hundreds of) decisions that we make in our everyday lives.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/1713426.Predictably_Irrational?ref=nav_sb_ss_1_8">Predictably Irrational</a> - Dan Ariely</li> <li><a href="https://www.goodreads.com/book/show/97084.Apathy_and_Other_Small_Victories?ref=nav_sb_ss_1_11">Apathy and Other Small Victories: A Novel</a> - Paul Neilan <ul> <li>This has to be the funniest book I have ever read.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/24612233-the-master-algorithm?ref=nav_sb_ss_1_13">The Master Algorithm</a> - Pedro Domingos <ul> <li>For someone working in machine learning (and being fairly familiar with the topics of the book), I found that the author gives some refreshing takes on the topics, that could be easily understood by non-machine learning audience.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/37542581-the-spy-and-the-traitor">The Spy and The Traitor: The Greatest Espionage Story in the History of Cold War</a> - Ben Macintyre <ul> <li>Who doesn’t love a gold old spy thriller ;)</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/6346975-moonwalking-with-einstein?ref=nav_sb_noss_l_8">Moonwalking with Einstein: The Art and Science of Remembering Everything</a> - Joshua Foer <ul> <li>This book is not about <em>moonwalking</em> or <em>Einstein</em>. I bought this just by looking at the title. However, it gives some great tips on training your memory for long term retention. In hindsight, as a PhD student now, a meta-lesson that I got from this is that a catchy title has important downstream effects in whether someone reads (or does not read) your work, given a split-second to decide.</li> </ul> </li> </ol> <p>People who know a bit about the field might be wondering how I have left out what, in my opinion, is the classic in behavioral economics - <a href="https://www.goodreads.com/book/show/11468377-thinking-fast-and-slow?ref=nav_sb_ss_1_9">Thinking, Fast and Slow</a> by Daniel Kahneman. I procrastinated on this for far too long (my gullible System 2 is the one to blame here) but finally, this is the book that I am currently reading.</p>]]></content><author><name></name></author><category term="books"/><summary type="html"><![CDATA[A list of books I read in 2020 and my brief opinion on them]]></summary></entry><entry><title type="html">List of Books I Read in 2022</title><link href="https://naga-karthik.github.io/blog/2023/books-in-2022/" rel="alternate" type="text/html" title="List of Books I Read in 2022"/><published>2023-08-08T22:27:00+00:00</published><updated>2023-08-08T22:27:00+00:00</updated><id>https://naga-karthik.github.io/blog/2023/books-in-2022</id><content type="html" xml:base="https://naga-karthik.github.io/blog/2023/books-in-2022/"><![CDATA[<p>This year was not productive in terms of the number of books I wanted to read. This is mainly because other things taking priority over short stints throughout the year, which left me unable to focus on reading much. While this might be the <em>generic</em> reason, one thing I learned is that choosing the right kind of book is really important, essentially leading to two outcomes - either you devour it because you find it <em>so</em> interesting, <em>or</em>, the book doesn’t generate interest and you try to finish it sluggishly at the expense of other books (or don’t at all). In my case, it was the latter for two books this year and I realized that life is just too short to be stuck with a book trying to finish it, while there are millions of other books waiting to be read, which could indeed be worth the time. So, without further ado, here’s my list for this year.</p> <ol> <li><a href="https://www.goodreads.com/book/show/4069.Man_s_Search_for_Meaning?from_search=true&amp;from_srp=true&amp;qid=GQ7CRFjbxa&amp;rank=1">Man’s Search for Meaning</a> - Viktor E. Frankl <ul> <li>This is a book that I think everyone should read at least once in their lifetime. While the atrocities in the Auschwitz concentration camps are described, which makes it a melancholy read in some pages, <em>but</em>, this book is more about hope and optimism and how we can overcome extreme suffering by having the right mindset.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/55723020-dopamine-nation?ac=1&amp;from_search=true&amp;qid=dRpk8eQie3&amp;rank=1">Dopamine Nation: Finding Balance in the Age of Indulgence</a> - Anna Lembke, MD <ul> <li>This was a recommendation I got from a specific Huberman Lab podcast on which the author was a guest speaker. Being a somewhat regular listener of the podcast, there are several occasions in which Dopamine is mentioned and how as a neurotransmitter, it plays a crucial role in our daily functioning. As a teaser, have you ever had that feeling where you just had a piece of cake and <em>surely</em>, one slice wasn’t enough and you want more? That’s precisely the high dopamine levels in your body talking.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/11468377-thinking-fast-and-slow?ac=1&amp;from_search=true&amp;qid=vxD0Oz0gYm&amp;rank=4">Thinking, Fast and Slow</a> - Daniel Kahneman <ul> <li><em>Unfinished</em>. Listening to others’ experiences, I think this book has a reputation of being hard to finish. And, for me, it has lived up to its reputation (I could only read 3/4ths of it). No disrespect to the author but, it seems like the book becomes repititive after a point and in my opinion, is quite dense right from the beginning. Moreover, I have moved on from my interest in behavioral economics, which was at its peak in 2020, and that’s also one of the reasons it was hard to finish this boook.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/61439040-1984?ac=1&amp;from_search=true&amp;qid=MZrPCLcnFZ&amp;rank=1">1984</a> - George Orwell <ul> <li><em>Unfinished</em>. I honestly don’t remember why I could not finish this book. Maybe because I started reading at the time where things happening in the real world seemed awfully similar to what is described in the book, so a sense of <em>déjà vu</em> swept in? I distinctly remember the Russia-Ukraine war starting at the time. In any case, if not this year, I will finish it some day and write about it here.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/40672036-digital-minimalism?ac=1&amp;from_search=true&amp;qid=YG0EE1hWGF&amp;rank=3">Digital Minimalism: Choosing a Focused Life in a Noisy World</a> - Cal Newport <ul> <li>Cal is also the author of the famous <a href="https://www.goodreads.com/book/show/25744928-deep-work">Deep Work</a> and has always had an unflinching stance on social media. This book talks about how the attention-seeking elements of these social media companies (mainly through their alarming colors, notification dings, and slot machine-like pull-down-for-more scroll features) are depriving us of the much-needed focus to do important work, which is otherwise spent by staying on their apps/websites. What I especially like in Cal’s writing is he always provides a list of actionable steps to achieve whatever the subject of converstaion is. For instance, a “Digital Declutter” is proposed, where, the challenge is to stay away social media for a calendar month. During this period, one has to explore/re-discover other activities that is meaningful and satisfying. After this refresh, optionally re-introduce select social media activities and make a plan as to how and to what extent will this be useful.</li> </ul> </li> <li><a href="https://www.goodreads.com/book/show/2195464.What_I_Talk_About_When_I_Talk_About_Running?ac=1&amp;from_search=true&amp;qid=CP64OmLThh&amp;rank=1">What I Talk About When I Talk About Running</a> - Haruki Murakami <ul> <li>A must-read for the runners and also to those who have only run short distances but someday would like to get into long-distance running. I loved this book so much that I decided to dedicate an <a href="https://naga-karthik.github.io/post/book-review/">entire post</a> to it.</li> </ul> </li> </ol> <p>With that, I realized that I am six books short of my target for this year. With the lessons learnt, I think at least twelve books (a book a month) is an achievable target for next year!</p>]]></content><author><name></name></author><category term="books"/><summary type="html"><![CDATA[A list of books I read in 2022 and my (brief) thoughts on them.]]></summary></entry><entry><title type="html">The book that resonated with me the most</title><link href="https://naga-karthik.github.io/blog/2023/murakami-running-book/" rel="alternate" type="text/html" title="The book that resonated with me the most"/><published>2023-08-08T22:27:00+00:00</published><updated>2023-08-08T22:27:00+00:00</updated><id>https://naga-karthik.github.io/blog/2023/murakami-running-book</id><content type="html" xml:base="https://naga-karthik.github.io/blog/2023/murakami-running-book/"><![CDATA[<p>I usually never write reviews about a particular thing but I thought this book requires one. Following high praise, I recently read “What I talk about when I talk about running” by Haruki Murakami. There are other well-known works by this author but I picked up this book without any second thought because of my experience being an (amateur) runner these past couple of years. I started running regularly during the pandemic and it is mainly a getaway for me when I am frustrated or anxious about something and feel this unstoppable need to get out there and … run. This impulse sometimes arrives at a time of bad weather (when it is windy or raining) and usually my urge for running trumps everything. I am not talking about short runs or races (although I do go out for short runs, when time is of the essence), but I am more interested in the aspect of endurance in long distance running, mainly for the reason that after a certain moment, like a flip of a switch, it suddenly transforms into something deeper, more contemplative, rather than physical exertion. Murakami puts it in a much better way and I quote, “No matter how mundane some action might appear, keep at it long enough and it becomes a contemplative, even meditative act” (this sentence alone made me consume the book much faster than my regular pace). People who do run long distances might agree that this does not happen in every run, you sometimes get into that state and sometimes it’s just pure exertion and you want to get back home, or, <em>not</em> run, as soon as possible.</p> <p>Given this background about my running, I was curious what someone has got to say about running in the first place as, I imagine it’s mostly different reasons for different people, some want to get in a better shape, some simply train for a race, and some (like myself) simply run as it frees them. I am glad that I picked this book as it turns out that Murakami has similar reasons for running (rather, <em>I</em> have similar reasons as Murakami’s). He talks about his experiences during his runs, how he started running (in his thirties), the training regime he follows before marathons (which he participated in at least once every year), how he made it through an ultra-marathon (62 miles/100 kms) in Japan, and how running has made him a better novelist that he is today. What I like most in his writing is his clever use of analogies that drive the exact feeling home. To give you one example, he writes, “on the highway of life you can’t always be on the fast lane”, written in the context of completing a race and competing against others. There are several others peppered throughout the book in various contexts that makes it a fun read.</p> <p>A question that seems like it should have a simple answer is <em>“What do you think when you are running?”</em>. However, in the author’s experience (and somewhat mine in a relatively smaller scale), this is not an easy question as there is no one specific thing that is thought about. Depending on how pleasant or unpleasant the weather, some thoughts go towards thinking about the weather, depending on how long you have been running, there’s a lingering thought on where’s the finish line. Ultimately, there is a whirlwind of thoughts, and none of them are anything worth mentioning. Again, Murakami puts it, “the thoughts that occur to me while I’m running are like the clouds in the sky. Clouds of different sizes. They come and they go, while the sky remains the same sky as always.”. I cannot overstate how many times I have witnessed exactly this while running. No matter how many times you look up, you’ll notice that the clouds are always taciturn.</p> <p>Another interesting element of this book lies in how he draws parallels between running and writing, and shares his thoughts on how he became a <em>running novelist</em>. For someone like me, aspiring to be a good writer, there are some great pieces of wisdom in this book. As described, the three qualities a novelist (or, more generally, a writer) should have are talent, focus and endurance. While talent is something that one is born with, focus and endurance are the ones that can be sharpened with training. One way to train both of them at the same time, is to sit at your desk everyday for an hour and focus on doing one thing. This has to be repeated <em>everyday</em> and even if you are not doing <em>anything</em>, just the act of sitting at your desk and concentrating will improve focus and gradually expand your limits. Much like long-distance running, writing also requires endurance (albeit, of a different form) because the process of focusing your mind, silencing away the distractions, creating something out of a blank page and choosing the right words is mentally taxing. Hence, just as we train our bodies for enduring long stretches of running, training our minds for enduring long bouts of writing is just as essential. Another great analogy - “I haven’t spotted any springs nearby. I have to pound the rock with a chisel and dig out a deep hole before I can locate the source of creativity.” - where, <em>spotting springs</em> refers to the abilities of people with inborn talent for writing, and the rest refers to his process of enduring in order to write novels.</p> <p>The real reason why I was curious to read this book is because I recently ran my first half-marathon and experienced some unusual/out-of-ordinary feelings towards the end of the race and I wondered if I could find something similar in a memoir about a person’s running experiences. Surely enough, I <em>did</em> find them. My finish time is not worth mentioning here (I tweeted about it if you’re curious :)), but, the process of training for a half-marathon, setting up weekly distance targets, your legs feeling sore all the time, dealing with all kinds of pain that were conveniently hiding until you started pushing more and coming up with remedies that will hopefully make the pain go away, are all part of the process as Murakami also recollects. Understandably, all of this, that is, the process of improving or perfecting each aspect of your running in the anticipation that it will be a smooth-sailing on D-Day (spoiler alert! it usually isn’t), takes a lot of time. However, a clever spin on this, as written in the book, is to think of it as a shortcut. Or, in his words, “sometimes taking the time is actually a shortcut.”.</p> <p>One thing that anyone running long-distances or training for a half/full marathon has to come to terms with is that there is a lot of pain involved. The sooner you internalize this the better because once you know that there will be pain, there will not be any lingering second thoughts on the choice of running long distances in the first place. The challenge, then, lies in how you manage to overcome that pain. As Murakami says, “If pain weren’t involved who in the world would ever go to the trouble of taking part in a marathon or a triathlon. It is precisely because of the pain, because we want to overcome that pain, that we can get the feeling of really being <em>alive</em> - or at least a partial sense of it.”.</p> <p>People might think, <em>“What is the point of all this running?”</em> because, from an outsider’s perspective, the pain and the stress that you’re putting your body through, is futile (another related question - <em>“Doesn’t it get boring after a while?”</em>). From my experience, every time I went on a longer run, I have learned something about myself and the limits of my body. There’s some despair as to why your body is not performing as you expect it to, but, at the same time, there’s some hope that you might just be able to work on those limitations and be ready for the race. I would like to end with a quote from the book (again), which is, “To be able to grasp something of value, sometimes you have to perform seemingly inefficient acts”.</p> <p>Thinking about my PhD, sometimes I wonder whether I chose long-distance running or long-distance running chose me as I can definitely draw some parallels between the kind of endeavors required for doing good in both of them. A topic for another time, perhaps. Anyways, without digressing further, this book is a must-read for all the readers out there sharing similar thoughts and experiences about and during running. I assure you, you will not regret reading it. On the contrary, you’d ask, why is this memoir so short?</p>]]></content><author><name></name></author><category term="books"/><summary type="html"><![CDATA[A long review of a memoir based on running.]]></summary></entry></feed>